{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import rel_entr, entr, xlogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available dataset\n",
    "datasets = [\"DTD\",\"EuroSAT\",\"GTSRB\",\"MNIST\",\"SVHN\",\"Caltech256\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_kl(P, Q):\n",
    "    return np.sum(rel_entr(P, Q), axis=1)\n",
    "\n",
    "# Calculate Entropy\n",
    "def calc_entropy(P):\n",
    "    return np.sum(entr(P), axis=1)\n",
    "\n",
    "# Calculate Cross-Entropy\n",
    "def calc_cross_ent(P, Q):\n",
    "    # return np.sum(entr(P,Q), axis=1)\n",
    "    # return -np.sum(P * np.log(Q), axis=1)\n",
    "    return -np.sum(xlogy(P,Q), axis=1)\n",
    "\n",
    "def calc_nll(p):\n",
    "    return -np.log(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df18_array shape: (1880, 47)\n",
      "df101_array shape: (1880, 47)\n",
      "flat_label shape: (1880,)\n",
      "df18_array shape: (5400, 10)\n",
      "df101_array shape: (5400, 10)\n",
      "flat_label shape: (5400,)\n",
      "df18_array shape: (6315, 43)\n",
      "df101_array shape: (6315, 43)\n",
      "flat_label shape: (6315,)\n",
      "df18_array shape: (5000, 10)\n",
      "df101_array shape: (5000, 10)\n",
      "flat_label shape: (5000,)\n",
      "df18_array shape: (13016, 10)\n",
      "df101_array shape: (13016, 10)\n",
      "flat_label shape: (13016,)\n",
      "df18_array shape: (3061, 257)\n",
      "df101_array shape: (3061, 257)\n",
      "flat_label shape: (3061,)\n"
     ]
    }
   ],
   "source": [
    "for ds in datasets:\n",
    "    df18 = pd.read_csv(f\"../Pred/{ds}_Resnet18.csv\")\n",
    "    df50 = pd.read_csv(f\"../Pred/{ds}_Resnet50.csv\")\n",
    "    df101 = pd.read_csv(f\"../Pred/{ds}_Resnet101.csv\")\n",
    "    label = pd.read_csv(f\"../Pred/target_{ds}.csv\")\n",
    "    prediction = pd.DataFrame({\n",
    "    \"pred18\": df18.idxmax(axis=1),\n",
    "    \"pred50\": df50.idxmax(axis=1),\n",
    "    \"pred101\": df101.idxmax(axis=1),\n",
    "    \"target\": label['target']\n",
    "    })\n",
    "    prediction[\"pred18\"] = prediction[\"pred18\"].str.extract('(\\d+)').astype(int)\n",
    "    prediction[\"pred50\"] = prediction[\"pred50\"].str.extract('(\\d+)').astype(int)\n",
    "    prediction[\"pred101\"] = prediction[\"pred101\"].str.extract('(\\d+)').astype(int)\n",
    "    prediction.to_csv(f\"prediction_{ds}.csv\")\n",
    "    unc_pred = pd.DataFrame()\n",
    "    unc_pred[\"kl_18_101\"] = calc_kl(df18,df101)\n",
    "    unc_pred[\"kl_101_18\"] = calc_kl(df101,df18)\n",
    "    unc_pred[\"ent_18\"] = calc_entropy(df18)\n",
    "    unc_pred[\"ent_101\"] = calc_entropy(df101)\n",
    "    unc_pred[\"ce_18_101\"] = calc_cross_ent(df18,df101)\n",
    "    unc_pred[\"ce_101_18\"] = calc_cross_ent(df101,df18)\n",
    "    # Calculate NLL and Brier Scores for each sample and add as columns\n",
    "    # ==============\n",
    "    flat_label = label['target'].values.flatten()\n",
    "    df18_array = df18.values\n",
    "    df101_array = df101.values\n",
    "    print(\"df18_array shape:\", df18_array.shape)\n",
    "    print(\"df101_array shape:\", df101_array.shape)\n",
    "    print(\"flat_label shape:\", flat_label.shape)\n",
    "    # Extracting the predicted probabilities for the true class labels\n",
    "    predicted_probabilities18 = df18_array[np.arange(df18_array.shape[0]), flat_label]\n",
    "    predicted_probabilities101 = df101_array[np.arange(df101_array.shape[0]), flat_label]\n",
    "    unc_pred[\"nll_18\"] = -np.log(predicted_probabilities18)\n",
    "    unc_pred[\"nll_101\"] = -np.log(predicted_probabilities101)\n",
    "    # Brier Scores:\n",
    "    unc_pred[\"brier_18\"] = (predicted_probabilities18-1)**2 + np.sum(np.square(df18),axis=1) - predicted_probabilities18**2\n",
    "    unc_pred[\"brier_101\"] = (predicted_probabilities101-1)**2 + np.sum(np.square(df101),axis=1) - predicted_probabilities101**2\n",
    "\n",
    "    unc_pred.to_csv(f\"uncertainty_{ds}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc340",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
