{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prefix = \"../ss/iWildCam_\"\n",
    "target_prefix = \"../ss/target_iWildCam_\"\n",
    "unc_out_prefix = \"ss/unc_\"\n",
    "pred_out_prefix = \"ss/pred_\"\n",
    "num_classes = 182\n",
    "test_sets=[\"ind\",\"ood\"]\n",
    "\n",
    "Resnet18_ls = [\"Resnet18ft0\", \"Resnet18ft2\", \"Resnet18ft3\"] #, \"Resnet18ft3\", \"Resnet18ft4\"\n",
    "Resnet34_ls = [\"Resnet34ft0\", \"Resnet34ft1\"]\n",
    "Resnet50_ls = [\"Resnet50ft0\",\"Resnet50ft2\"]\n",
    "Resnet101_ls = [\"Resnet101ft0\",\"Resnet101ft1\"]\n",
    "Resnet152_ls = [\"Resnet152ft0\"]\n",
    "\n",
    "M_lp_ls = [\"Resnet50lp0\",\"Resnet50lp2\"] # deprecated\n",
    "L_lp_ls = [\"Resnet101lp0\",\"Resnet101lp1\"] # deprecated\n",
    "\n",
    "Include_Ensembles = False\n",
    "Include_Duos = True\n",
    "Include_LPFT = False\n",
    "\n",
    "S_model_ls = Resnet18_ls\n",
    "M_model_ls = Resnet50_ls\n",
    "L_model_ls = Resnet101_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor_categories available based on inclusion settings: dict_keys(['S', 'M', 'L', 'SM_duo', 'SL_duo', 'ML_duo'])\n"
     ]
    }
   ],
   "source": [
    "# Initialize predictor_categories dictionary\n",
    "predictor_categories = {\n",
    "    \"S\": S_model_ls,\n",
    "    \"M\": M_model_ls,\n",
    "    \"L\": L_model_ls\n",
    "}\n",
    "if Include_LPFT:\n",
    "    predictor_categories.update({\n",
    "        \"Mlp\": M_lp_ls,\n",
    "        \"Llp\": L_lp_ls\n",
    "    })\n",
    "if Include_Ensembles:\n",
    "    predictor_categories.update({f\"EnsM={m}\": [] for m in range(2, len(S_model_ls) + 1)})\n",
    "if Include_Duos:\n",
    "    predictor_categories.update({\n",
    "        \"SM_duo\": [],\n",
    "        \"SL_duo\": [],\n",
    "        \"ML_duo\": []\n",
    "    })\n",
    "if Include_LPFT:\n",
    "    predictor_categories.update({\n",
    "        \"lpft_M\": [],\n",
    "        \"lpft_L\": []\n",
    "    })\n",
    "    \n",
    "print(f\"predictor_categories available based on inclusion settings: {predictor_categories.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Ensembles / Duos / LPFTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ind:\n",
      "Generating SM Duos\n",
      "Generating SL Duos\n",
      "Generating ML Duos\n",
      "Working on ood:\n",
      "Generating SM Duos\n",
      "Generating SL Duos\n",
      "Generating ML Duos\n",
      "{\n",
      "  \"S\": [\n",
      "    \"Resnet50ft0\",\n",
      "    \"Resnet50ft2\"\n",
      "  ],\n",
      "  \"M\": [\n",
      "    \"Resnet101ft0\",\n",
      "    \"Resnet101ft1\"\n",
      "  ],\n",
      "  \"L\": [\n",
      "    \"Resnet152ft0\"\n",
      "  ],\n",
      "  \"SM_duo\": [\n",
      "    \"SM_duo_Resnet50ft0_Resnet101ft0\",\n",
      "    \"SM_duo_Resnet50ft0_Resnet101ft1\",\n",
      "    \"SM_duo_Resnet50ft2_Resnet101ft0\",\n",
      "    \"SM_duo_Resnet50ft2_Resnet101ft1\"\n",
      "  ],\n",
      "  \"SL_duo\": [\n",
      "    \"SL_duo_Resnet50ft0_Resnet152ft0\",\n",
      "    \"SL_duo_Resnet50ft2_Resnet152ft0\"\n",
      "  ],\n",
      "  \"ML_duo\": [\n",
      "    \"ML_duo_Resnet101ft0_Resnet152ft0\",\n",
      "    \"ML_duo_Resnet101ft1_Resnet152ft0\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for testtype in test_sets:\n",
    "    print(f\"Working on {testtype}:\")\n",
    "    \n",
    "    if Include_Ensembles:\n",
    "        print(\"Generating ensembles from S models\")\n",
    "        for m in range(2, len(S_model_ls)+1):\n",
    "            print(f\"{m=}...\")\n",
    "            for comb in itertools.combinations(S_model_ls, m):\n",
    "                ensemble_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{model}.csv\") for model in comb])\n",
    "                ensemble_name = utils.generate_ensemble_name(f\"EnsS_{m}\", comb)\n",
    "                utils.save_ensemble_predictions(pred_prefix, testtype, ensemble_name, ensemble_pred)\n",
    "                if testtype==test_sets[0]: \n",
    "                    predictor_categories[f\"EnsM={m}\"].append(ensemble_name)\n",
    "\n",
    "    if Include_Duos:\n",
    "        print(\"Generating SM Duos\")\n",
    "        for s_model in S_model_ls:\n",
    "            for m_model in M_model_ls:\n",
    "                sm_duo_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{s_model}.csv\"), pd.read_csv(f\"{pred_prefix}{testtype}_{m_model}.csv\")])\n",
    "                sm_duo_name = utils.generate_ensemble_name(\"SM_duo\", [s_model, m_model])\n",
    "                utils.save_ensemble_predictions(pred_prefix, testtype, sm_duo_name, sm_duo_pred)\n",
    "                if testtype == test_sets[0]:\n",
    "                    predictor_categories[\"SM_duo\"].append(sm_duo_name)\n",
    "        print(\"Generating SL Duos\") \n",
    "        for s_model in S_model_ls:\n",
    "            for l_model in L_model_ls:\n",
    "                sl_duo_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{s_model}.csv\"), pd.read_csv(f\"{pred_prefix}{testtype}_{l_model}.csv\")])\n",
    "                sl_duo_name = utils.generate_ensemble_name(\"SL_duo\", [s_model, l_model])\n",
    "                utils.save_ensemble_predictions(pred_prefix, testtype, sl_duo_name, sl_duo_pred)\n",
    "                if testtype == test_sets[0]:\n",
    "                    predictor_categories[\"SL_duo\"].append(sl_duo_name)\n",
    "        print(\"Generating ML Duos\") \n",
    "        for m_model in M_model_ls:\n",
    "            for l_model in L_model_ls:\n",
    "                ml_duo_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{m_model}.csv\"), pd.read_csv(f\"{pred_prefix}{testtype}_{l_model}.csv\")])\n",
    "                ml_duo_name = utils.generate_ensemble_name(\"ML_duo\", [m_model, l_model])\n",
    "                utils.save_ensemble_predictions(pred_prefix, testtype, ml_duo_name, ml_duo_pred)\n",
    "                if testtype == test_sets[0]:\n",
    "                    predictor_categories[\"ML_duo\"].append(ml_duo_name)\n",
    "\n",
    "    if Include_LPFT:\n",
    "        print(\"Generating lpft-M duos\")\n",
    "        for m_ft, m_lp in zip(M_model_ls, M_lp_ls):\n",
    "            lpft_m_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{m_lp}.csv\"), pd.read_csv(f\"{pred_prefix}{testtype}_{m_ft}.csv\")])\n",
    "            lpft_m_name = utils.generate_ensemble_name(\"lpft_M\", [m_lp,m_ft])\n",
    "            utils.save_ensemble_predictions(pred_prefix, testtype, lpft_m_name, lpft_m_pred)\n",
    "            if testtype == test_sets[0]:\n",
    "                predictor_categories[\"lpft_M\"].append(lpft_m_name)\n",
    "        print(\"Generating lpft-L duos\")\n",
    "        for l_ft, l_lp in zip(L_model_ls, L_lp_ls):\n",
    "            lpft_l_pred = utils.softvote([pd.read_csv(f\"{pred_prefix}{testtype}_{l_lp}.csv\"), pd.read_csv(f\"{pred_prefix}{testtype}_{l_ft}.csv\")])\n",
    "            lpft_l_name = utils.generate_ensemble_name(\"lpft_L\", [l_lp,l_ft])\n",
    "            utils.save_ensemble_predictions(pred_prefix, testtype, lpft_l_name, lpft_l_pred)\n",
    "            if testtype == test_sets[0]:\n",
    "                predictor_categories[\"lpft_L\"].append(lpft_l_name)\n",
    "\n",
    "# Save the predictor_categories dictionary for use in the evaluation script\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"w\") as file:\n",
    "    json.dump(predictor_categories, file)\n",
    "print(json.dumps(predictor_categories, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {F1, Acc, Brier, Ece, Mce} of raw models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testtype='ind'\n",
      "Evaluating S\n",
      "Evaluating M\n",
      "Evaluating L\n",
      "Evaluating SM_duo\n",
      "Evaluating SL_duo\n",
      "Evaluating ML_duo\n",
      "testtype='ood'\n",
      "Evaluating S\n",
      "Evaluating M\n",
      "Evaluating L\n",
      "Evaluating SM_duo\n",
      "Evaluating SL_duo\n",
      "Evaluating ML_duo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Set</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1</th>\n",
       "      <th>Brier</th>\n",
       "      <th>ECE</th>\n",
       "      <th>MCE</th>\n",
       "      <th>Predictor Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resnet50ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.784155</td>\n",
       "      <td>0.453848</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.160803</td>\n",
       "      <td>0.402448</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resnet50ft2</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.774467</td>\n",
       "      <td>0.429172</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.175750</td>\n",
       "      <td>0.486047</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resnet101ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.769438</td>\n",
       "      <td>0.439821</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.193279</td>\n",
       "      <td>0.459607</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resnet101ft1</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.788938</td>\n",
       "      <td>0.434513</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.156467</td>\n",
       "      <td>0.344540</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.767844</td>\n",
       "      <td>0.440999</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.217192</td>\n",
       "      <td>0.489624</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.783419</td>\n",
       "      <td>0.459042</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.174338</td>\n",
       "      <td>0.450863</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.792494</td>\n",
       "      <td>0.456093</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.156989</td>\n",
       "      <td>0.338561</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.780231</td>\n",
       "      <td>0.440576</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.450724</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.786608</td>\n",
       "      <td>0.437025</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.162329</td>\n",
       "      <td>0.369944</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.784155</td>\n",
       "      <td>0.459447</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.183429</td>\n",
       "      <td>0.433786</td>\n",
       "      <td>SL_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.774957</td>\n",
       "      <td>0.430206</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.195482</td>\n",
       "      <td>0.495538</td>\n",
       "      <td>SL_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.776183</td>\n",
       "      <td>0.456510</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.200171</td>\n",
       "      <td>0.480385</td>\n",
       "      <td>ML_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>0.782561</td>\n",
       "      <td>0.451902</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.186197</td>\n",
       "      <td>0.412309</td>\n",
       "      <td>ML_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Resnet50ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.690028</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.457808</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Resnet50ft2</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.673249</td>\n",
       "      <td>0.317713</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.225206</td>\n",
       "      <td>0.501607</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.700661</td>\n",
       "      <td>0.325159</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.181689</td>\n",
       "      <td>0.455460</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.687948</td>\n",
       "      <td>0.333713</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.198618</td>\n",
       "      <td>0.467592</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.687014</td>\n",
       "      <td>0.337773</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.219621</td>\n",
       "      <td>0.521188</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.708794</td>\n",
       "      <td>0.331774</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.181035</td>\n",
       "      <td>0.444750</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.701783</td>\n",
       "      <td>0.346879</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.192136</td>\n",
       "      <td>0.461228</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.694959</td>\n",
       "      <td>0.339121</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.196492</td>\n",
       "      <td>0.460630</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.688860</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.206407</td>\n",
       "      <td>0.490369</td>\n",
       "      <td>SM_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.700895</td>\n",
       "      <td>0.348386</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.196724</td>\n",
       "      <td>0.483241</td>\n",
       "      <td>SL_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.688673</td>\n",
       "      <td>0.335075</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.213315</td>\n",
       "      <td>0.518206</td>\n",
       "      <td>SL_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.706013</td>\n",
       "      <td>0.343158</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.187822</td>\n",
       "      <td>0.481605</td>\n",
       "      <td>ML_duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>0.702064</td>\n",
       "      <td>0.340240</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.194405</td>\n",
       "      <td>0.508705</td>\n",
       "      <td>ML_duo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model Test Set       Acc        F1     Brier  \\\n",
       "0                        Resnet50ft0      ind  0.784155  0.453848  0.001948   \n",
       "1                        Resnet50ft2      ind  0.774467  0.429172  0.002056   \n",
       "2                       Resnet101ft0      ind  0.769438  0.439821  0.002136   \n",
       "3                       Resnet101ft1      ind  0.788938  0.434513  0.001927   \n",
       "4                       Resnet152ft0      ind  0.767844  0.440999  0.002178   \n",
       "5    SM_duo_Resnet50ft0_Resnet101ft0      ind  0.783419  0.459042  0.001989   \n",
       "6    SM_duo_Resnet50ft0_Resnet101ft1      ind  0.792494  0.456093  0.001877   \n",
       "7    SM_duo_Resnet50ft2_Resnet101ft0      ind  0.780231  0.440576  0.002019   \n",
       "8    SM_duo_Resnet50ft2_Resnet101ft1      ind  0.786608  0.437025  0.001918   \n",
       "9    SL_duo_Resnet50ft0_Resnet152ft0      ind  0.784155  0.459447  0.001999   \n",
       "10   SL_duo_Resnet50ft2_Resnet152ft0      ind  0.774957  0.430206  0.002054   \n",
       "11  ML_duo_Resnet101ft0_Resnet152ft0      ind  0.776183  0.456510  0.002091   \n",
       "12  ML_duo_Resnet101ft1_Resnet152ft0      ind  0.782561  0.451902  0.002000   \n",
       "13                       Resnet50ft0      ood  0.690028  0.314250  0.002660   \n",
       "14                       Resnet50ft2      ood  0.673249  0.317713  0.002886   \n",
       "15                      Resnet101ft0      ood  0.700661  0.325159  0.002526   \n",
       "16                      Resnet101ft1      ood  0.687948  0.333713  0.002685   \n",
       "17                      Resnet152ft0      ood  0.687014  0.337773  0.002717   \n",
       "18   SM_duo_Resnet50ft0_Resnet101ft0      ood  0.708794  0.331774  0.002476   \n",
       "19   SM_duo_Resnet50ft0_Resnet101ft1      ood  0.701783  0.346879  0.002568   \n",
       "20   SM_duo_Resnet50ft2_Resnet101ft0      ood  0.694959  0.339121  0.002626   \n",
       "21   SM_duo_Resnet50ft2_Resnet101ft1      ood  0.688860  0.336064  0.002709   \n",
       "22   SL_duo_Resnet50ft0_Resnet152ft0      ood  0.700895  0.348386  0.002551   \n",
       "23   SL_duo_Resnet50ft2_Resnet152ft0      ood  0.688673  0.335075  0.002706   \n",
       "24  ML_duo_Resnet101ft0_Resnet152ft0      ood  0.706013  0.343158  0.002496   \n",
       "25  ML_duo_Resnet101ft1_Resnet152ft0      ood  0.702064  0.340240  0.002564   \n",
       "\n",
       "         ECE       MCE Predictor Category  \n",
       "0   0.160803  0.402448                  S  \n",
       "1   0.175750  0.486047                  S  \n",
       "2   0.193279  0.459607                  M  \n",
       "3   0.156467  0.344540                  M  \n",
       "4   0.217192  0.489624                  L  \n",
       "5   0.174338  0.450863             SM_duo  \n",
       "6   0.156989  0.338561             SM_duo  \n",
       "7   0.175225  0.450724             SM_duo  \n",
       "8   0.162329  0.369944             SM_duo  \n",
       "9   0.183429  0.433786             SL_duo  \n",
       "10  0.195482  0.495538             SL_duo  \n",
       "11  0.200171  0.480385             ML_duo  \n",
       "12  0.186197  0.412309             ML_duo  \n",
       "13  0.200521  0.457808                  S  \n",
       "14  0.225206  0.501607                  S  \n",
       "15  0.181689  0.455460                  M  \n",
       "16  0.198618  0.467592                  M  \n",
       "17  0.219621  0.521188                  L  \n",
       "18  0.181035  0.444750             SM_duo  \n",
       "19  0.192136  0.461228             SM_duo  \n",
       "20  0.196492  0.460630             SM_duo  \n",
       "21  0.206407  0.490369             SM_duo  \n",
       "22  0.196724  0.483241             SL_duo  \n",
       "23  0.213315  0.518206             SL_duo  \n",
       "24  0.187822  0.481605             ML_duo  \n",
       "25  0.194405  0.508705             ML_duo  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the predictor_categories dictionary\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "\n",
    "metrics_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Test Set\": [],\n",
    "    \"Acc\": [],\n",
    "    \"F1\": [],\n",
    "    \"Brier\": [],\n",
    "    \"ECE\": [],\n",
    "    \"MCE\": [],\n",
    "    \"Predictor Category\": []\n",
    "}\n",
    "\n",
    "for testtype in test_sets:\n",
    "    print(f\"{testtype=}\")\n",
    "    label = pd.read_csv(f\"{target_prefix}{testtype}.csv\")\n",
    "    \n",
    "    for category, models in predictor_categories.items():\n",
    "        print(f\"Evaluating {category}\")\n",
    "        metrics_dict = utils.evaluate_models(models, label, pred_prefix, testtype, metrics_dict, category, num_classes)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv(f\"{pred_out_prefix}metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating uncertainty DataFrame for ind...\n",
      "Calculating entropy for all models\n",
      "Calculating cross-entropy(M||S)\n",
      "Calculating cross-entropy(L||S)\n",
      "Calculating cross-entropy(L||M)\n",
      "Saved uncertainty DataFrame for ind.\n",
      "Generating uncertainty DataFrame for ood...\n",
      "Calculating entropy for all models\n",
      "Calculating cross-entropy(M||S)\n",
      "Calculating cross-entropy(L||S)\n",
      "Calculating cross-entropy(L||M)\n",
      "Saved uncertainty DataFrame for ood.\n"
     ]
    }
   ],
   "source": [
    "# Load the predictor_categories dictionary\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "\n",
    "# Generate the uncertainty DataFrame\n",
    "for testtype in test_sets:\n",
    "    print(f\"Generating uncertainty DataFrame for {testtype}...\")\n",
    "    unc = pd.DataFrame()\n",
    "    \n",
    "    # Calculate entropy for all models\n",
    "    print(f\"Calculating entropy for all models\")\n",
    "    for category, models in predictor_categories.items():\n",
    "        for model in models:\n",
    "            predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{model}.csv\")\n",
    "            unc[f\"entr_{model}\"] = utils.calc_entr_torch(predictions)\n",
    "            unc[f\"softmax_res_{model}\"] = utils.softmax_response_unc(predictions)\n",
    "    \n",
    "    # Calculate cross-entropy for specific pairs\n",
    "    if Include_Duos:\n",
    "        print(f\"Calculating cross-entropy(M||S)\")\n",
    "        for s_model in S_model_ls:\n",
    "            for m_model in M_model_ls:\n",
    "                m_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{m_model}.csv\")\n",
    "                s_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{s_model}.csv\")\n",
    "                unc[f\"ce_{m_model}_{s_model}\"] = utils.calc_cross_entr_torch(m_predictions, s_predictions)\n",
    "                unc[f\"entr_{m_model}+ce_{m_model}_{s_model}\"] = unc[f\"entr_{m_model}\"] + unc[f\"ce_{m_model}_{s_model}\"]\n",
    "                sm_duo_name = f\"SM_duo_{s_model}_{m_model}\"\n",
    "                unc[f\"entr_{sm_duo_name}+ce_{m_model}_{s_model}\"] = unc[f\"entr_{sm_duo_name}\"] + unc[f\"ce_{m_model}_{s_model}\"]\n",
    "\n",
    "        print(f\"Calculating cross-entropy(L||S)\")\n",
    "        for s_model in S_model_ls:\n",
    "            for l_model in L_model_ls:\n",
    "                l_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{l_model}.csv\")\n",
    "                s_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{s_model}.csv\")\n",
    "                unc[f\"ce_{l_model}_{s_model}\"] = utils.calc_cross_entr_torch(l_predictions, s_predictions)\n",
    "                unc[f\"entr_{l_model}+ce_{l_model}_{s_model}\"] = unc[f\"entr_{l_model}\"] + unc[f\"ce_{l_model}_{s_model}\"]\n",
    "                sl_duo_name = f\"SL_duo_{s_model}_{l_model}\"\n",
    "                unc[f\"entr_{sl_duo_name}+ce_{l_model}_{s_model}\"] = unc[f\"entr_{sl_duo_name}\"] + unc[f\"ce_{l_model}_{s_model}\"]\n",
    "\n",
    "        print(f\"Calculating cross-entropy(L||M)\")\n",
    "        for m_model in M_model_ls:\n",
    "            for l_model in L_model_ls:\n",
    "                l_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{l_model}.csv\")\n",
    "                m_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{m_model}.csv\")\n",
    "                unc[f\"ce_{l_model}_{m_model}\"] = utils.calc_cross_entr_torch(l_predictions, m_predictions)\n",
    "                unc[f\"entr_{l_model}+ce_{l_model}_{m_model}\"] = unc[f\"entr_{l_model}\"] + unc[f\"ce_{l_model}_{m_model}\"]\n",
    "                ml_duo_name = f\"ML_duo_{m_model}_{l_model}\"\n",
    "                unc[f\"entr_{ml_duo_name}+ce_{l_model}_{m_model}\"] = unc[f\"entr_{ml_duo_name}\"] + unc[f\"ce_{l_model}_{m_model}\"]\n",
    "\n",
    "    if Include_LPFT:\n",
    "        print(f\"Calculating cross-entropy(Mft||Mlp)\")\n",
    "        for m_ft, m_lp in zip(M_model_ls, M_lp_ls):\n",
    "            m_ft_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{m_ft}.csv\")\n",
    "            m_lp_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{m_lp}.csv\")\n",
    "            unc[f\"ce_{m_ft}_{m_lp}\"] = utils.calc_cross_entr_torch(m_ft_predictions, m_lp_predictions)\n",
    "            unc[f\"entr_{m_ft}+ce_{m_ft}_{m_lp}\"] = unc[f\"entr_{m_ft}\"] + unc[f\"ce_{m_ft}_{m_lp}\"]\n",
    "\n",
    "        print(f\"Calculating cross-entropyLft|Llp)\")\n",
    "        for l_ft, l_lp in zip(L_model_ls, L_lp_ls):\n",
    "            l_ft_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{l_ft}.csv\")\n",
    "            l_lp_predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{l_lp}.csv\")\n",
    "            unc[f\"ce_{l_ft}_{l_lp}\"] = utils.calc_cross_entr_torch(l_ft_predictions, l_lp_predictions)\n",
    "            unc[f\"entr_{l_ft}+ce_{l_ft}_{l_lp}\"] = unc[f\"entr_{l_ft}\"] + unc[f\"ce_{l_ft}_{l_lp}\"]\n",
    "\n",
    "    # Save the uncertainty DataFrame\n",
    "    unc.to_csv(f\"{unc_out_prefix}{testtype}.csv\", index=False)\n",
    "    print(f\"Saved uncertainty DataFrame for {testtype}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction DataFrame for ind...\n",
      "Saved prediction DataFrame for ind.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred_Resnet50ft0</th>\n",
       "      <th>pred_Resnet50ft2</th>\n",
       "      <th>pred_Resnet101ft0</th>\n",
       "      <th>pred_Resnet101ft1</th>\n",
       "      <th>pred_Resnet152ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft0_Resnet101ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft0_Resnet101ft1</th>\n",
       "      <th>pred_SM_duo_Resnet50ft2_Resnet101ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft2_Resnet101ft1</th>\n",
       "      <th>pred_SL_duo_Resnet50ft0_Resnet152ft0</th>\n",
       "      <th>pred_SL_duo_Resnet50ft2_Resnet152ft0</th>\n",
       "      <th>pred_ML_duo_Resnet101ft0_Resnet152ft0</th>\n",
       "      <th>pred_ML_duo_Resnet101ft1_Resnet152ft0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target pred_Resnet50ft0 pred_Resnet50ft2 pred_Resnet101ft0  \\\n",
       "0       1                1                1                 1   \n",
       "1       1                1                1                 1   \n",
       "2       1                1                1                 1   \n",
       "\n",
       "  pred_Resnet101ft1 pred_Resnet152ft0 pred_SM_duo_Resnet50ft0_Resnet101ft0  \\\n",
       "0                 1                 1                                    1   \n",
       "1                 1                 1                                    1   \n",
       "2                 1                 1                                    1   \n",
       "\n",
       "  pred_SM_duo_Resnet50ft0_Resnet101ft1 pred_SM_duo_Resnet50ft2_Resnet101ft0  \\\n",
       "0                                    1                                    1   \n",
       "1                                    1                                    1   \n",
       "2                                    1                                    1   \n",
       "\n",
       "  pred_SM_duo_Resnet50ft2_Resnet101ft1 pred_SL_duo_Resnet50ft0_Resnet152ft0  \\\n",
       "0                                    1                                    1   \n",
       "1                                    1                                    1   \n",
       "2                                    1                                    1   \n",
       "\n",
       "  pred_SL_duo_Resnet50ft2_Resnet152ft0 pred_ML_duo_Resnet101ft0_Resnet152ft0  \\\n",
       "0                                    1                                     1   \n",
       "1                                    1                                     1   \n",
       "2                                    1                                     1   \n",
       "\n",
       "  pred_ML_duo_Resnet101ft1_Resnet152ft0  \n",
       "0                                     1  \n",
       "1                                     1  \n",
       "2                                     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction DataFrame for ood...\n",
      "Saved prediction DataFrame for ood.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred_Resnet50ft0</th>\n",
       "      <th>pred_Resnet50ft2</th>\n",
       "      <th>pred_Resnet101ft0</th>\n",
       "      <th>pred_Resnet101ft1</th>\n",
       "      <th>pred_Resnet152ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft0_Resnet101ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft0_Resnet101ft1</th>\n",
       "      <th>pred_SM_duo_Resnet50ft2_Resnet101ft0</th>\n",
       "      <th>pred_SM_duo_Resnet50ft2_Resnet101ft1</th>\n",
       "      <th>pred_SL_duo_Resnet50ft0_Resnet152ft0</th>\n",
       "      <th>pred_SL_duo_Resnet50ft2_Resnet152ft0</th>\n",
       "      <th>pred_ML_duo_Resnet101ft0_Resnet152ft0</th>\n",
       "      <th>pred_ML_duo_Resnet101ft1_Resnet152ft0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target pred_Resnet50ft0 pred_Resnet50ft2 pred_Resnet101ft0  \\\n",
       "0     113               68              113               113   \n",
       "1     113               68               68               113   \n",
       "2       0                0                0                 0   \n",
       "\n",
       "  pred_Resnet101ft1 pred_Resnet152ft0 pred_SM_duo_Resnet50ft0_Resnet101ft0  \\\n",
       "0                 0                 0                                  113   \n",
       "1                68                 0                                  113   \n",
       "2                 0                 0                                    0   \n",
       "\n",
       "  pred_SM_duo_Resnet50ft0_Resnet101ft1 pred_SM_duo_Resnet50ft2_Resnet101ft0  \\\n",
       "0                                   68                                  113   \n",
       "1                                   68                                  113   \n",
       "2                                    0                                    0   \n",
       "\n",
       "  pred_SM_duo_Resnet50ft2_Resnet101ft1 pred_SL_duo_Resnet50ft0_Resnet152ft0  \\\n",
       "0                                  113                                    0   \n",
       "1                                   68                                   68   \n",
       "2                                    0                                    0   \n",
       "\n",
       "  pred_SL_duo_Resnet50ft2_Resnet152ft0 pred_ML_duo_Resnet101ft0_Resnet152ft0  \\\n",
       "0                                    0                                     0   \n",
       "1                                    0                                     0   \n",
       "2                                    0                                     0   \n",
       "\n",
       "  pred_ML_duo_Resnet101ft1_Resnet152ft0  \n",
       "0                                     0  \n",
       "1                                     0  \n",
       "2                                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the predictor_categories dictionary\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "\n",
    "# Generate prediction DataFrame\n",
    "for testtype in test_sets:\n",
    "    print(f\"Generating prediction DataFrame for {testtype}...\")\n",
    "    pred_df = pd.read_csv(f\"{target_prefix}{testtype}.csv\")\n",
    "\n",
    "    for category, models in predictor_categories.items():\n",
    "        for model in models:\n",
    "            predictions = pd.read_csv(f\"{pred_prefix}{testtype}_{model}.csv\")\n",
    "            pred_df[f\"pred_{model}\"] = predictions.idxmax(axis=1).str.extract('(\\d+)')\n",
    "\n",
    "    # Save the prediction DataFrame\n",
    "    pred_df.to_csv(f\"{pred_out_prefix}{testtype}.csv\", index=False)\n",
    "    print(f\"Saved prediction DataFrame for {testtype}.\")\n",
    "    display(pred_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness Prediction AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AUROC for ind...\n",
      "Evaluating AUROC for ood...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Category</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Set</th>\n",
       "      <th>Uncertainty Measure</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(self)+CE(self||smaller)</td>\n",
       "      <td>0.862590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(self)+CE(self||smaller)</td>\n",
       "      <td>0.862810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.862642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.860148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(self)+CE(self||smaller)</td>\n",
       "      <td>0.858866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.903631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.902074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>Entr(larger)+CE(self||smaller)</td>\n",
       "      <td>0.887975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.895630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.895084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor Category                             Model Test Set  \\\n",
       "0                   L  ML_duo_Resnet101ft0_Resnet152ft0      ind   \n",
       "1                   L  ML_duo_Resnet101ft1_Resnet152ft0      ind   \n",
       "2                   L                      Resnet152ft0      ind   \n",
       "3                   L                      Resnet152ft0      ind   \n",
       "4                   L   SL_duo_Resnet50ft0_Resnet152ft0      ind   \n",
       "..                ...                               ...      ...   \n",
       "79             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0      ood   \n",
       "80             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0      ood   \n",
       "81             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "82             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "83             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "\n",
       "               Uncertainty Measure     AUROC  \n",
       "0     Entr(self)+CE(self||smaller)  0.862590  \n",
       "1     Entr(self)+CE(self||smaller)  0.862810  \n",
       "2                             entr  0.862642  \n",
       "3                          softmax  0.860148  \n",
       "4     Entr(self)+CE(self||smaller)  0.858866  \n",
       "..                             ...       ...  \n",
       "79                            entr  0.903631  \n",
       "80                         softmax  0.902074  \n",
       "81  Entr(larger)+CE(self||smaller)  0.887975  \n",
       "82                            entr  0.895630  \n",
       "83                         softmax  0.895084  \n",
       "\n",
       "[84 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load predictor categories\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "    \n",
    "# Initialize the AUROC results dictionary\n",
    "auroc_results = {\n",
    "    \"Predictor Category\": [],\n",
    "    \"Model\": [],\n",
    "    \"Test Set\": [],\n",
    "    \"Uncertainty Measure\": [],\n",
    "    \"AUROC\": []\n",
    "}\n",
    "\n",
    "# Main evaluation loop\n",
    "for testtype in test_sets:\n",
    "    print(f\"Evaluating AUROC for {testtype}...\")\n",
    "    pred_df = pd.read_csv(f\"{pred_out_prefix}{testtype}.csv\")\n",
    "    unc_df = pd.read_csv(f\"{unc_out_prefix}{testtype}.csv\")\n",
    "\n",
    "    for category, models in predictor_categories.items():\n",
    "        for model in models:\n",
    "            pred_column = f\"pred_{model}\"\n",
    "            unc_measures = [f\"entr_{model}\", f\"softmax_res_{model}\"]\n",
    "\n",
    "            if category in [\"S\", \"M\", \"L\", \"SM_duo\", \"SL_duo\", \"ML_duo\", \"lpft_M\", \"lpft_L\"]:\n",
    "                for unc_measure in unc_measures:\n",
    "                    auroc_value = utils.calculate_auroc(pred_df, unc_df, pred_column, \"target\", unc_measure)\n",
    "                    auroc_results = utils.update_auroc_results(auroc_results, model, testtype, category, unc_measure.split(\"_\")[0], auroc_value)\n",
    "\n",
    "            if category in [\"SM_duo\", \"SL_duo\", \"ML_duo\"]:\n",
    "                model_ls = model.split('_')[2:]\n",
    "                unc_larger_as_predictor = f\"entr_{model_ls[1]}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "                auroc_value = utils.calculate_auroc(pred_df, unc_df, pred_column, \"target\", unc_larger_as_predictor)\n",
    "                auroc_results = utils.update_auroc_results(auroc_results, model, testtype, category.split(\"_\")[0][1], \"Entr(self)+CE(self||smaller)\", auroc_value)\n",
    "                \n",
    "                unc_ens_as_predictor = f\"entr_{model}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "                auroc_value = utils.calculate_auroc(pred_df, unc_df, pred_column, \"target\", unc_ens_as_predictor)\n",
    "                auroc_results = utils.update_auroc_results(auroc_results, model, testtype, category, \"Entr(larger)+CE(self||smaller)\", auroc_value)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame and display it\n",
    "auroc_df = pd.DataFrame(auroc_results).sort_values([\"Test Set\",\"Predictor Category\",\"Model\",\"Uncertainty Measure\"], ignore_index=True)\n",
    "display(auroc_df)\n",
    "\n",
    "# Save the AUROC results to a CSV file\n",
    "auroc_df.to_csv(f\"{unc_out_prefix}auroc_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Cov AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating F1-Coverage tradeoff AUC for ind...\n",
      "Evaluating F1-Coverage tradeoff AUC for ood...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Category</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Set</th>\n",
       "      <th>Uncertainty Measure</th>\n",
       "      <th>F1-Cov AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>73.341543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>74.213089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>entr</td>\n",
       "      <td>71.565166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>softmax</td>\n",
       "      <td>63.546453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>ind</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>73.772689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>entr</td>\n",
       "      <td>67.512915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>ood</td>\n",
       "      <td>softmax</td>\n",
       "      <td>67.091710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>68.219377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>entr</td>\n",
       "      <td>69.335904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>ood</td>\n",
       "      <td>softmax</td>\n",
       "      <td>69.004903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor Category                             Model Test Set  \\\n",
       "0                   L  ML_duo_Resnet101ft0_Resnet152ft0      ind   \n",
       "1                   L  ML_duo_Resnet101ft1_Resnet152ft0      ind   \n",
       "2                   L                      Resnet152ft0      ind   \n",
       "3                   L                      Resnet152ft0      ind   \n",
       "4                   L   SL_duo_Resnet50ft0_Resnet152ft0      ind   \n",
       "..                ...                               ...      ...   \n",
       "79             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0      ood   \n",
       "80             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0      ood   \n",
       "81             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "82             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "83             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1      ood   \n",
       "\n",
       "                 Uncertainty Measure  F1-Cov AUC  \n",
       "0   Entr(larger)+CE(larger||smaller)   73.341543  \n",
       "1   Entr(larger)+CE(larger||smaller)   74.213089  \n",
       "2                               entr   71.565166  \n",
       "3                            softmax   63.546453  \n",
       "4   Entr(larger)+CE(larger||smaller)   73.772689  \n",
       "..                               ...         ...  \n",
       "79                              entr   67.512915  \n",
       "80                           softmax   67.091710  \n",
       "81    Entr(self)+CE(larger||smaller)   68.219377  \n",
       "82                              entr   69.335904  \n",
       "83                           softmax   69.004903  \n",
       "\n",
       "[84 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load predictor categories\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "    \n",
    "# Initialize the F1-Coverage tradeoff results dictionary\n",
    "f1_cov_results = {\n",
    "    \"Predictor Category\": [],\n",
    "    \"Model\": [],\n",
    "    \"Test Set\": [],\n",
    "    \"Uncertainty Measure\": [],\n",
    "    \"F1-Cov AUC\": []\n",
    "}\n",
    "\n",
    "cov_range = np.arange(1, 100)\n",
    "\n",
    "\n",
    "# Main evaluation loop\n",
    "for testtype in test_sets:\n",
    "    print(f\"Evaluating F1-Coverage tradeoff AUC for {testtype}...\")\n",
    "    pred_df = pd.read_csv(f\"{pred_out_prefix}{testtype}.csv\")\n",
    "    unc_df = pd.read_csv(f\"{unc_out_prefix}{testtype}.csv\")\n",
    "\n",
    "    for category, models in predictor_categories.items():\n",
    "        for model in models:\n",
    "            pred_column = f\"pred_{model}\"\n",
    "            unc_measures = [f\"entr_{model}\", f\"softmax_res_{model}\"]\n",
    "\n",
    "            # Calculate and update F1-Coverage AUC values for each uncertainty measure\n",
    "            for unc_measure in unc_measures:\n",
    "                f1_cov_auc_value = utils.calculate_f1_cov_auc(pred_df, unc_df, pred_column, \"target\", unc_measure, cov_range)\n",
    "                f1_cov_results = utils.update_f1_cov_results(f1_cov_results, model, testtype, category, unc_measure.split(\"_\")[0], f1_cov_auc_value)\n",
    "\n",
    "            if category in [\"SM_duo\", \"SL_duo\", \"ML_duo\"]:\n",
    "                model_ls = model.split('_')[2:]\n",
    "                combined_unc_measure = f\"entr_{model}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "                f1_cov_auc_value_combined = utils.calculate_f1_cov_auc(pred_df, unc_df, pred_column, \"target\", combined_unc_measure, cov_range)\n",
    "                f1_cov_results = utils.update_f1_cov_results(f1_cov_results, model, testtype, category, \"Entr(self)+CE(larger||smaller)\", f1_cov_auc_value_combined)\n",
    "\n",
    "                larger_unc_measure = f\"entr_{model_ls[1]}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "                f1_cov_auc_value_larger = utils.calculate_f1_cov_auc(pred_df, unc_df, f\"pred_{model_ls[1]}\", \"target\", larger_unc_measure, cov_range)\n",
    "                f1_cov_results = utils.update_f1_cov_results(f1_cov_results, model, testtype, category.split(\"_\")[0][1], \"Entr(larger)+CE(larger||smaller)\", f1_cov_auc_value_larger)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame and display it\n",
    "f1_cov_df = pd.DataFrame(f1_cov_results).sort_values([\"Test Set\",\"Predictor Category\",\"Model\",\"Uncertainty Measure\"], ignore_index=True)\n",
    "display(f1_cov_df)\n",
    "\n",
    "# Save the F1-Coverage AUC results to a CSV file\n",
    "f1_cov_df.to_csv(f\"{unc_out_prefix}f1_cov_auc_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD Detection AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Category</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Set</th>\n",
       "      <th>Uncertainty Measure</th>\n",
       "      <th>AUROC OOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.617089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.624123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.620199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.613903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.631984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L</td>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.622232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.628289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.621670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.625223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.617597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.629119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.626435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.627068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(larger)+CE(larger||smaller)</td>\n",
       "      <td>0.625529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.617102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.622558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.616207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.624057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.622530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ML_duo</td>\n",
       "      <td>ML_duo_Resnet101ft1_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.615796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S</td>\n",
       "      <td>Resnet50ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.625165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S</td>\n",
       "      <td>Resnet50ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.619045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>S</td>\n",
       "      <td>Resnet50ft2</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.620984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>S</td>\n",
       "      <td>Resnet50ft2</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.615105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.630396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.621021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft0_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.614772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.621098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SL_duo</td>\n",
       "      <td>SL_duo_Resnet50ft2_Resnet152ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.611834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.628566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.625591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.618822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.627409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.626563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft0_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.619526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.621454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft0</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.614855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>Entr(self)+CE(larger||smaller)</td>\n",
       "      <td>0.625575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>entr</td>\n",
       "      <td>0.622328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SM_duo</td>\n",
       "      <td>SM_duo_Resnet50ft2_Resnet101ft1</td>\n",
       "      <td>combined</td>\n",
       "      <td>softmax</td>\n",
       "      <td>0.616051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor Category                             Model  Test Set  \\\n",
       "0                   L  ML_duo_Resnet101ft0_Resnet152ft0  combined   \n",
       "1                   L  ML_duo_Resnet101ft1_Resnet152ft0  combined   \n",
       "2                   L                      Resnet152ft0  combined   \n",
       "3                   L                      Resnet152ft0  combined   \n",
       "4                   L   SL_duo_Resnet50ft0_Resnet152ft0  combined   \n",
       "5                   L   SL_duo_Resnet50ft2_Resnet152ft0  combined   \n",
       "6                   M                      Resnet101ft0  combined   \n",
       "7                   M                      Resnet101ft0  combined   \n",
       "8                   M                      Resnet101ft1  combined   \n",
       "9                   M                      Resnet101ft1  combined   \n",
       "10                  M   SM_duo_Resnet50ft0_Resnet101ft0  combined   \n",
       "11                  M   SM_duo_Resnet50ft0_Resnet101ft1  combined   \n",
       "12                  M   SM_duo_Resnet50ft2_Resnet101ft0  combined   \n",
       "13                  M   SM_duo_Resnet50ft2_Resnet101ft1  combined   \n",
       "14             ML_duo  ML_duo_Resnet101ft0_Resnet152ft0  combined   \n",
       "15             ML_duo  ML_duo_Resnet101ft0_Resnet152ft0  combined   \n",
       "16             ML_duo  ML_duo_Resnet101ft0_Resnet152ft0  combined   \n",
       "17             ML_duo  ML_duo_Resnet101ft1_Resnet152ft0  combined   \n",
       "18             ML_duo  ML_duo_Resnet101ft1_Resnet152ft0  combined   \n",
       "19             ML_duo  ML_duo_Resnet101ft1_Resnet152ft0  combined   \n",
       "20                  S                       Resnet50ft0  combined   \n",
       "21                  S                       Resnet50ft0  combined   \n",
       "22                  S                       Resnet50ft2  combined   \n",
       "23                  S                       Resnet50ft2  combined   \n",
       "24             SL_duo   SL_duo_Resnet50ft0_Resnet152ft0  combined   \n",
       "25             SL_duo   SL_duo_Resnet50ft0_Resnet152ft0  combined   \n",
       "26             SL_duo   SL_duo_Resnet50ft0_Resnet152ft0  combined   \n",
       "27             SL_duo   SL_duo_Resnet50ft2_Resnet152ft0  combined   \n",
       "28             SL_duo   SL_duo_Resnet50ft2_Resnet152ft0  combined   \n",
       "29             SL_duo   SL_duo_Resnet50ft2_Resnet152ft0  combined   \n",
       "30             SM_duo   SM_duo_Resnet50ft0_Resnet101ft0  combined   \n",
       "31             SM_duo   SM_duo_Resnet50ft0_Resnet101ft0  combined   \n",
       "32             SM_duo   SM_duo_Resnet50ft0_Resnet101ft0  combined   \n",
       "33             SM_duo   SM_duo_Resnet50ft0_Resnet101ft1  combined   \n",
       "34             SM_duo   SM_duo_Resnet50ft0_Resnet101ft1  combined   \n",
       "35             SM_duo   SM_duo_Resnet50ft0_Resnet101ft1  combined   \n",
       "36             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0  combined   \n",
       "37             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0  combined   \n",
       "38             SM_duo   SM_duo_Resnet50ft2_Resnet101ft0  combined   \n",
       "39             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1  combined   \n",
       "40             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1  combined   \n",
       "41             SM_duo   SM_duo_Resnet50ft2_Resnet101ft1  combined   \n",
       "\n",
       "                 Uncertainty Measure  AUROC OOD  \n",
       "0   Entr(larger)+CE(larger||smaller)   0.617089  \n",
       "1   Entr(larger)+CE(larger||smaller)   0.624123  \n",
       "2                               entr   0.620199  \n",
       "3                            softmax   0.613903  \n",
       "4   Entr(larger)+CE(larger||smaller)   0.631984  \n",
       "5   Entr(larger)+CE(larger||smaller)   0.622232  \n",
       "6                               entr   0.628289  \n",
       "7                            softmax   0.621670  \n",
       "8                               entr   0.625223  \n",
       "9                            softmax   0.617597  \n",
       "10  Entr(larger)+CE(larger||smaller)   0.629119  \n",
       "11  Entr(larger)+CE(larger||smaller)   0.626435  \n",
       "12  Entr(larger)+CE(larger||smaller)   0.627068  \n",
       "13  Entr(larger)+CE(larger||smaller)   0.625529  \n",
       "14    Entr(self)+CE(larger||smaller)   0.617102  \n",
       "15                              entr   0.622558  \n",
       "16                           softmax   0.616207  \n",
       "17    Entr(self)+CE(larger||smaller)   0.624057  \n",
       "18                              entr   0.622530  \n",
       "19                           softmax   0.615796  \n",
       "20                              entr   0.625165  \n",
       "21                           softmax   0.619045  \n",
       "22                              entr   0.620984  \n",
       "23                           softmax   0.615105  \n",
       "24    Entr(self)+CE(larger||smaller)   0.630396  \n",
       "25                              entr   0.621021  \n",
       "26                           softmax   0.614772  \n",
       "27    Entr(self)+CE(larger||smaller)   0.621098  \n",
       "28                              entr   0.617900  \n",
       "29                           softmax   0.611834  \n",
       "30    Entr(self)+CE(larger||smaller)   0.628566  \n",
       "31                              entr   0.625591  \n",
       "32                           softmax   0.618822  \n",
       "33    Entr(self)+CE(larger||smaller)   0.627409  \n",
       "34                              entr   0.626563  \n",
       "35                           softmax   0.619526  \n",
       "36    Entr(self)+CE(larger||smaller)   0.625700  \n",
       "37                              entr   0.621454  \n",
       "38                           softmax   0.614855  \n",
       "39    Entr(self)+CE(larger||smaller)   0.625575  \n",
       "40                              entr   0.622328  \n",
       "41                           softmax   0.616051  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load predictor categories\n",
    "with open(f\"{pred_out_prefix}predictor_categories.json\", \"r\") as file:\n",
    "    predictor_categories = json.load(file)\n",
    "    \n",
    "# Initialize the AUROC OOD results dictionary\n",
    "auroc_ood_results = {\n",
    "    \"Predictor Category\": [],\n",
    "    \"Model\": [],\n",
    "    \"Test Set\": [],\n",
    "    \"Uncertainty Measure\": [],\n",
    "    \"AUROC OOD\": []\n",
    "}\n",
    "\n",
    "# Combine in-distribution and out-of-distribution data\n",
    "pred_df_ind = pd.read_csv(f\"{pred_out_prefix}ind.csv\")\n",
    "unc_df_ind = pd.read_csv(f\"{unc_out_prefix}ind.csv\")\n",
    "pred_df_ood = pd.read_csv(f\"{pred_out_prefix}ood.csv\")\n",
    "unc_df_ood = pd.read_csv(f\"{unc_out_prefix}ood.csv\")\n",
    "\n",
    "pred_df_ind[\"test_type\"] = \"ind\"\n",
    "pred_df_ood[\"test_type\"] = \"ood\"\n",
    "\n",
    "pred_df_combined = pd.concat([pred_df_ood, pred_df_ind], ignore_index=True)\n",
    "unc_df_combined = pd.concat([unc_df_ood, unc_df_ind], ignore_index=True)\n",
    "\n",
    "# Calculate AUROC for OOD detection\n",
    "for category, models in predictor_categories.items():\n",
    "    for model in models:\n",
    "        pred_column = f\"pred_{model}\"\n",
    "        unc_measures = [f\"entr_{model}\", f\"softmax_res_{model}\"]\n",
    "\n",
    "        # Calculate and update AUROC OOD values for each uncertainty measure\n",
    "        for unc_measure in unc_measures:\n",
    "            auroc_ood_value = utils.calculate_auroc_ood(pred_df_combined, unc_df_combined, pred_column, unc_measure)\n",
    "            auroc_ood_results = utils.update_auroc_ood_results(auroc_ood_results, model, category, unc_measure.split(\"_\")[0], auroc_ood_value)\n",
    "\n",
    "        if category in [\"SM_duo\", \"SL_duo\", \"ML_duo\", \"lpft_M\", \"lpft_L\"]:\n",
    "            model_ls = model.split('_')[2:]\n",
    "            combined_unc_measure = f\"entr_{model}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "            auroc_ood_value_combined = utils.calculate_auroc_ood(pred_df_combined, unc_df_combined, pred_column, combined_unc_measure)\n",
    "            auroc_ood_results = utils.update_auroc_ood_results(auroc_ood_results, model, category, \"Entr(self)+CE(larger||smaller)\", auroc_ood_value_combined)\n",
    "\n",
    "            larger_unc_measure = f\"entr_{model_ls[1]}+ce_{model_ls[1]}_{model_ls[0]}\"\n",
    "            auroc_ood_value_larger = utils.calculate_auroc_ood(pred_df_combined, unc_df_combined, f\"pred_{model_ls[1]}\", larger_unc_measure)\n",
    "            auroc_ood_results = utils.update_auroc_ood_results(auroc_ood_results, model, category.split(\"_\")[0][1], \"Entr(larger)+CE(larger||smaller)\", auroc_ood_value_larger)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame and display it\n",
    "auroc_ood_df = pd.DataFrame(auroc_ood_results).sort_values([\"Test Set\",\"Predictor Category\",\"Model\",\"Uncertainty Measure\"], ignore_index=True)\n",
    "display(auroc_ood_df)\n",
    "\n",
    "# Save the AUROC OOD results to a CSV file\n",
    "auroc_ood_df.to_csv(f\"{unc_out_prefix}auroc_ood_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
